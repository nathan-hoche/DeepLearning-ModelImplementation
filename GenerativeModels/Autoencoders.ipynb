{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f32ec5d6750>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load dataset\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "\n",
    "# plot the first image in the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, Reshape, UpSampling2D\n",
    "\n",
    "class Encoder():\n",
    "    def __init__(self, in_shape=(28,28,1)):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(16, (3,3), activation='relu', padding='same', input_shape=in_shape))\n",
    "        self.model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder():\n",
    "    def __init__(self, in_shape=(32,)) -> None:\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dense(784, activation='sigmoid'))\n",
    "        self.model.add(Reshape((28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecorder():\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.model = Sequential()\n",
    "        self.model.add(self.encoder.model)\n",
    "        self.model.add(self.decoder.model)\n",
    "        self.model.summary()\n",
    "        self.model.compile(loss=\"mse\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, X, y, epochs=3, batch_size=128):\n",
    "        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def plotAllImage(self, X):\n",
    "        fakeData = self.model.predict(X)\n",
    "        for i in range(len(X)):\n",
    "            plt.axis('off')\n",
    "            plt.imshow(fakeData[i], cmap='gray')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 32)        4640      \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,220,320\n",
      "Trainable params: 3,220,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_18 (Sequential)  (None, 32)                3220320   \n",
      "                                                                 \n",
      " sequential_19 (Sequential)  (None, 28, 28, 1)         106416    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,326,736\n",
      "Trainable params: 3,326,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 6988.4937 - accuracy: 0.3965\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6982.3193 - accuracy: 0.3681\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6978.4438 - accuracy: 0.3734\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6975.5059 - accuracy: 0.3701\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6973.1035 - accuracy: 0.3782\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6970.6621 - accuracy: 0.3757\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6969.5098 - accuracy: 0.3726\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6968.4507 - accuracy: 0.3732\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6967.4517 - accuracy: 0.3754\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6966.6689 - accuracy: 0.3790\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6965.9346 - accuracy: 0.3815\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6965.4814 - accuracy: 0.3796\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6965.3521 - accuracy: 0.3822\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6965.1968 - accuracy: 0.3822\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6964.7373 - accuracy: 0.3828\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6964.2573 - accuracy: 0.3844\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6964.0996 - accuracy: 0.3882\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6963.5483 - accuracy: 0.3889\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6963.3345 - accuracy: 0.3878\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6963.2441 - accuracy: 0.3866\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6963.2417 - accuracy: 0.3865\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6963.2393 - accuracy: 0.3869\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6963.2261 - accuracy: 0.3868\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6963.1636 - accuracy: 0.3865\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6962.9976 - accuracy: 0.3866\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6962.9414 - accuracy: 0.3867\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6962.9414 - accuracy: 0.3867\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6962.9404 - accuracy: 0.3878\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6962.9331 - accuracy: 0.3895\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6962.8589 - accuracy: 0.3895\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6962.6792 - accuracy: 0.3897\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6962.3545 - accuracy: 0.3879\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6962.3267 - accuracy: 0.3903\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6962.3257 - accuracy: 0.3913\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6962.3218 - accuracy: 0.3923\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6962.2104 - accuracy: 0.3920\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6962.0317 - accuracy: 0.3908\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6962.0361 - accuracy: 0.3931\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.8979 - accuracy: 0.3926\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.8765 - accuracy: 0.3937\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.8745 - accuracy: 0.3945\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6961.8735 - accuracy: 0.3959\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6961.8726 - accuracy: 0.3972\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.8652 - accuracy: 0.3963\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.8652 - accuracy: 0.3962\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.8652 - accuracy: 0.3963\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.8652 - accuracy: 0.3965\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.8643 - accuracy: 0.3965\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.8662 - accuracy: 0.3964\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6961.8301 - accuracy: 0.3958\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.7437 - accuracy: 0.3956\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.7437 - accuracy: 0.3956\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.7437 - accuracy: 0.3955\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.7437 - accuracy: 0.3955\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.7427 - accuracy: 0.3964\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6961.7373 - accuracy: 0.3968\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.7026 - accuracy: 0.3958\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.7026 - accuracy: 0.3958\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6961.7017 - accuracy: 0.3955\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.7012 - accuracy: 0.3965\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.7012 - accuracy: 0.3965\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.7002 - accuracy: 0.3968\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.5015 - accuracy: 0.3966\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.4873 - accuracy: 0.3967\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.4888 - accuracy: 0.3967\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.4873 - accuracy: 0.3967\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.4692 - accuracy: 0.3962\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.2285 - accuracy: 0.3952\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.2275 - accuracy: 0.3951\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.2275 - accuracy: 0.3955\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.2271 - accuracy: 0.3962\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.2271 - accuracy: 0.3962\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.2236 - accuracy: 0.3972\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.3963\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1816 - accuracy: 0.3963\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.3964\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1812 - accuracy: 0.3975\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.1802 - accuracy: 0.3980\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1802 - accuracy: 0.3990\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.1802 - accuracy: 0.3990\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1802 - accuracy: 0.3992\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1812 - accuracy: 0.4002\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4002\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1816 - accuracy: 0.4002\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.1816 - accuracy: 0.4002\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4002\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1812 - accuracy: 0.4003\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1816 - accuracy: 0.4003\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1816 - accuracy: 0.4004\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1802 - accuracy: 0.4015\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1802 - accuracy: 0.4016\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1650 - accuracy: 0.4007\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.1621 - accuracy: 0.4004\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1626 - accuracy: 0.4005\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1626 - accuracy: 0.4004\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6961.1626 - accuracy: 0.4005\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1626 - accuracy: 0.4005\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6961.1626 - accuracy: 0.4005\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.1533 - accuracy: 0.4002\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3997\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.0400 - accuracy: 0.3997\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3995\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0400 - accuracy: 0.3995\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0400 - accuracy: 0.3995\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0400 - accuracy: 0.3997\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0400 - accuracy: 0.3997\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.0400 - accuracy: 0.3996\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6961.0386 - accuracy: 0.4008\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0386 - accuracy: 0.4009\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.0386 - accuracy: 0.4010\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6961.0386 - accuracy: 0.4009\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6961.0386 - accuracy: 0.4009\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.9224 - accuracy: 0.4000\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.9224 - accuracy: 0.4000\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.7227 - accuracy: 0.3995\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.7090 - accuracy: 0.3993\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.7090 - accuracy: 0.3993\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.7075 - accuracy: 0.3993\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.7075 - accuracy: 0.3995\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.7090 - accuracy: 0.3997\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.7075 - accuracy: 0.3995\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.6777 - accuracy: 0.3994\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4214 - accuracy: 0.3989\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4194 - accuracy: 0.4003\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4194 - accuracy: 0.4003\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4180 - accuracy: 0.4016\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.4180 - accuracy: 0.4016\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4180 - accuracy: 0.4017\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4194 - accuracy: 0.4020\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4189 - accuracy: 0.4029\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6960.4189 - accuracy: 0.4028\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.4189 - accuracy: 0.4029\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4180 - accuracy: 0.4030\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4204 - accuracy: 0.4037\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4194 - accuracy: 0.4036\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4189 - accuracy: 0.4029\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4189 - accuracy: 0.4029\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4189 - accuracy: 0.4030\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.4170 - accuracy: 0.4042\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4238 - accuracy: 0.4048\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.4180 - accuracy: 0.4043\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.4180 - accuracy: 0.4044\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6960.4170 - accuracy: 0.4043\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.4170 - accuracy: 0.4044\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.4131 - accuracy: 0.4042\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 6960.3936 - accuracy: 0.4032\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3936 - accuracy: 0.4033\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6960.3926 - accuracy: 0.4045\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4046\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4046\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3926 - accuracy: 0.4047\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6960.3921 - accuracy: 0.4047\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3921 - accuracy: 0.4052\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6960.3950 - accuracy: 0.4060\n",
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not 5.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m encoder_decoder \u001b[39m=\u001b[39m EncoderDecorder(encoder, decoder)\n\u001b[1;32m      5\u001b[0m history \u001b[39m=\u001b[39m encoder_decoder\u001b[39m.\u001b[39mtrain(X_train[:\u001b[39m100\u001b[39m], X_train[:\u001b[39m100\u001b[39m], epochs\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m encoder_decoder\u001b[39m.\u001b[39;49mplotAllImage(X_train[:\u001b[39m10\u001b[39;49m])\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mEncoderDecorder.plotAllImage\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     15\u001b[0m fakeData \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(fakeData\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> 17\u001b[0m     plt\u001b[39m.\u001b[39;49msubplot(fakeData\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, fakeData\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m'\u001b[39m\u001b[39moff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     plt\u001b[39m.\u001b[39mimshow(fakeData[i], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/pyplot.py:1323\u001b[0m, in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m fig \u001b[39m=\u001b[39m gcf()\n\u001b[1;32m   1322\u001b[0m \u001b[39m# First, search for an existing subplot with a matching spec.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m key \u001b[39m=\u001b[39m SubplotSpec\u001b[39m.\u001b[39;49m_from_subplot_args(fig, args)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m fig\u001b[39m.\u001b[39maxes:\n\u001b[1;32m   1326\u001b[0m     \u001b[39m# if we found an Axes at the position sort out if we can re-use it\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[39mif\u001b[39;00m ax\u001b[39m.\u001b[39mget_subplotspec() \u001b[39m==\u001b[39m key:\n\u001b[1;32m   1328\u001b[0m         \u001b[39m# if the user passed no kwargs, re-use\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/gridspec.py:587\u001b[0m, in \u001b[0;36mSubplotSpec._from_subplot_args\u001b[0;34m(figure, args)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m     \u001b[39mraise\u001b[39;00m _api\u001b[39m.\u001b[39mnargs_error(\u001b[39m\"\u001b[39m\u001b[39msubplot\u001b[39m\u001b[39m\"\u001b[39m, takes\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1 or 3\u001b[39m\u001b[39m\"\u001b[39m, given\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(args))\n\u001b[0;32m--> 587\u001b[0m gs \u001b[39m=\u001b[39m GridSpec\u001b[39m.\u001b[39;49m_check_gridspec_exists(figure, rows, cols)\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m gs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m     gs \u001b[39m=\u001b[39m GridSpec(rows, cols, figure\u001b[39m=\u001b[39mfigure)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/gridspec.py:226\u001b[0m, in \u001b[0;36mGridSpecBase._check_gridspec_exists\u001b[0;34m(figure, nrows, ncols)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[39mreturn\u001b[39;00m gs\n\u001b[1;32m    225\u001b[0m \u001b[39m# else gridspec not found:\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m \u001b[39mreturn\u001b[39;00m GridSpec(nrows, ncols, figure\u001b[39m=\u001b[39;49mfigure)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/gridspec.py:379\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[0;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhspace \u001b[39m=\u001b[39m hspace\n\u001b[1;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure \u001b[39m=\u001b[39m figure\n\u001b[0;32m--> 379\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(nrows, ncols,\n\u001b[1;32m    380\u001b[0m                  width_ratios\u001b[39m=\u001b[39;49mwidth_ratios,\n\u001b[1;32m    381\u001b[0m                  height_ratios\u001b[39m=\u001b[39;49mheight_ratios)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/matplotlib/gridspec.py:49\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[0;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(nrows, Integral) \u001b[39mor\u001b[39;00m nrows \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     50\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of rows must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mnrows\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(ncols, Integral) \u001b[39mor\u001b[39;00m ncols \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of columns must be a positive integer, not \u001b[39m\u001b[39m{\u001b[39;00mncols\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of rows must be a positive integer, not 5.0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "encoder_decoder = EncoderDecorder(encoder, decoder)\n",
    "\n",
    "history = encoder_decoder.train(X_train[:100], X_train[:100], epochs=300, batch_size=128)\n",
    "\n",
    "encoder_decoder.plotAllImage(X_train[:10])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
